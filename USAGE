TABLE OF CONTENTS
=================

I.  Scripts
II.  BETSY Quick Reference
III.  BETSY Tutorial
IV.  BETSY Cookbook
V.  Managing Cache



Please email if there are any problems with this document.

Thanks,
Jeff
jeffrey.t.chang@uth.tmc.edu



I.  SCRIPTS
===========

This is a list of some scripts that may be useful.  You can get a
description of how to run it by typing:

    <script name> -h


GENERAL UTILITIES
slice_matrix.py        Matrix utilities, e.g. normalize, cluster, filter.
slice_annot.py         Utilities for annotation files (tab-delimited, columns).
align_matrices.py      Align matrices or annotation files.


DATA ANALYSIS
calc_venn.py           Does a Venn diagram comparison of gene sets.
find_diffexp_genes.py  Calculates differential expression of genes.
gsea.py                Command line interface to GSEA.
pybinreg.py            Command line interface to BinReg 2.0.
scoresig.py            Score all signatures in a gene expression file.
score_geneset.py


MAKING FIGURES
arrayplot2.py          Makes heatmaps from gene expression files.
histoplot.py           Histograms.
lineplot.py            Expression of genes across each sample.
pcaplot.py             PCA of arrays.
boxplot.               Distribution of gene expression for samples.




II.  BETSY QUICK REFERENCE
==========================

betsy_run.py -h    Show a help message with description of arguments.
betsy_run.py       Browse the knowledge base.

Some useful flags:
  --num_cores <int>         Set the maximum number of cores to use.
  --receipt <filename>      Save a record of the analysis run (as a text file).
  --network_png <filename>  Save the graph with pipelines as a PNG file.


BETSY is concurrency safe.  You can run multiple instances
simultaneously.  If two instances are operating on the same data, they
won't do the same calculations, and they won't overwrite each other's
results in the cache.  (They may overwrite files specified by the
user, e.g. in --network_png).




III.  BETSY TUTORIAL
====================

The main interface to the BETSY expert system is through the
betsy_run.py script.  In this system, you specify the desired output
(e.g. a gene expression data set), and work with BETSY to refine the
pipeline until you come upon one that fits your needs.  Here is an
example interaction with the system to generate a clustered heatmap of
a gene expression data set.

1.  First, query the BETSY knowledge base for the DataTypes that can
be produced.

$ betsy_run.py

In the output, I see that the DataType for generating a heatmap is
called a "Heatmap".


2.  Ask BETSY to create a network that produces a Heatmap.  I do this
by specifying an "--output" parameter.

$ betsy_run.py --network_png graph.png --output Heatmap
# Will run for a minute or two.

This will show (in the terminal) all the possible combination of
"inputs" that can be used to generate a Heatmap.  As you can see,
there are many possibilities.

The "--network_png" argument tells BETSY to create a file "graph.png"
in the local directory that shows the graph of the pipelines that can
create a Heatmap.

Zooming in, we can see that there are light and dark grey nodes.  The
light ones indicate Data objects, and the dark ones are Modules that
can convert one type of Data to another.  They are connected by
arrows, that indicate which Data are inputs and outputs to each
module.  On the bottom of the graph is a Heatmap object.  BETSY can
take as input any one (or combination) of Data objects as inputs to
create a Heatmap.

To get a description of what these Data and Module nodes are, we can
examine the BETSY knowledge base:
$ betsy_run.py


3.  We would like to use a gene expression file that is currently
stored in the GEO database.  Therefore, we will refine the pipeline by
telling BETSY that we would like to use a "GEOSeries" (seen in the
results from the terminal in the previous step).

$ betsy_run.py --network_png graph.png \
    --input GEOSeries \
    --output Heatmap

This tells BETSY that we would like to generate a Heatmap from a
GEOSeries.  Know that it knows the desired input, the graph will show
the pipeline(s) that run from the input(s) to the output.

The order of the arguments to betsy_run.py can be important.
"--input" goes before "--output".



4.  Reading through the messages that BETSY printed to the terminal,
we see lines:
    Missing --mattr: download_GEO_family_soft requires attribute "GSEID".
    Missing --mattr: download_geo_seriesmatrix requires attribute "GSEID".
    Missing --mattr: download_geo_supplement requires attribute "GSEID".

This means that these modules require an attribute "GSEID" to run.  In
this case, it is asking for the identifier of the GEO record to
download.

"--mattr" stands for (m)odule (attr)ibute, which is a parameter that
changes how a module runs.  Some of the attributes are required
(e.g. here, we can't download data from GEO without knowing which data
to download), and sometimes attributes are optional.  They are not
required to run, but may change the module's behavior (e.g. when we
generate the heatmap, there are attributes to specify the color).

We now specify which data to download.

$ betsy_run.py --network_png graph.png \
    --input GEOSeries \
    --output Heatmap \
    --mattr GSEID=GSE14934

Although --mattr can go anywhere in the argument list, I usually put
them at the end.

There are no more messages about missing --mattr arguments.  We now
see the line:
    Add --run when ready to run the analysis.

This means that BETSY has enough information to generate the pipeline
and is ready to run it.


5.  We now take one more look at graph.png to examine the
pipeline(s) created and make sure it is what we intended.  Since it
looks good, we now ask BETSY to run the pipeline by adding the "--run"
argument.

Although it is not necessary, we will also add a "--receipt" argument
so that BETSY will generate a text file record of what it did, and an
"--output_file" argument to tell BETSY where to save the output file.

$ betsy_run.py --network_png graph.png \
    --input GEOSeries \
    --output Heatmap --output_file heatmap.png \
    --receipt "GSE14934.heatmap.txt" \
    --mattr GSEID=GSE14934 \
    --run
# This will run for ~5 minutes.

If this ran successfully, BETSY:
a.  Downloaded the user submitted gene expression data for GEO recore
    GSE14934.
b.  Downloaded the annotations for this GEO record.
c.  Merged the gene expression with annotations.
d.  Log normalized the data.
e.  Plotted the heatmap.

Also, graph.png is now updated to show the pipeline that was run.


6.  Unfortuntely, this generated a heatmap that is too big to open on
my computer.  (Using ImageMagick, I can make a smaller file that can
open: convert heatmap.png -resize x1024 heatmap_smaller.png).  It
looks like BETSY made a heatmap that includes every gene on the array,
which isn't what I wanted.  The purpose of the heatmap is to show the
general expression pattern across the samples of the data set.  Thus,
it is better to filter for the most meaningful genes.  Specifically, I
would like to filter for just the genes with highest variance.

Examining the graph, I see that the Heatmap is generated from a
SignalFile DataType.  Further, the SignalFile has an attribute
called "filter_and_threshold" that is set to "no".  (TODO: BETSY needs
to define each of these attributes clearly.)  I'll asked BETSY to
filter the genes by setting this to "yes".

"filter_and_threshold" is an attribute on the SignalFile DataType.  To
ask BETSY to filter the SignalFile set, I use the "--dattr" or (d)ata
(attr)ibute argument thusly:

$ betsy_run.py --network_png graph.png \
    --input GEOSeries \
    --output Heatmap --output_file heatmap.png \
    --dattr SignalFile.filter_and_threshold=yes \
    --receipt "GSE14934.heatmap.txt" \
    --mattr GSEID=GSE14934

Again, the order of the arguments is important.  --dattr arguments
usually apply to the most recent DataType (specified as an --input or
--output).  So if GEOSeries had an attribute I wanted to set, I would
add the --dattr argument for the GEOSeries directly after the --input
argument.  However, in this case, since I would like to set the
attribute of a DataType in the graph that is not specified in either
the --input or --output, I put that at the end, after both --input and
--output.

After running this, I examine the graph closely to see what has
changed.  I verify that the "filter_and_threshold" data attribute is
now "yes".  Looking through the graph, I see that this is set by the
module "filter_and_threshold_genes", with several module attributes.
Looking through the BETSY knowledge base (by running betsy_run.py), I
find a description for what each of these attributes do.  To select
the most highly varying genes, I add "--mattr genes_with_highest_var=250".

$ betsy_run.py --network_png graph.png \
    --input GEOSeries \
    --output Heatmap --output_file heatmap.png \
    --dattr SignalFile.filter_and_threshold=yes \
    --receipt "GSE14934.heatmap.txt" \
    --mattr GSEID=GSE14934 \
    --mattr genes_with_highest_var=250

After verifying that the graph looks OK, I added "--run" to run this
pipeline.


7.  After the analysis is finished, the heatmap is starting to look
closer.  One thing that is commonly done when comparing the relative
patterns of expression, is to center and normalize the genes.  Using a
procedure similar to step 6, examining the graph and knowledge base,
we find that the way to ask BETSY to do this is:

$ betsy_run.py --network_png graph.png \
    --input GEOSeries \
    --output Heatmap --output_file heatmap.png \
    --dattr SignalFile.filter_and_threshold=yes \
    --dattr SignalFile.gene_center=mean \
    --dattr SignalFile.gene_normalize=variance \
    --receipt "GSE14934.heatmap.txt" \
    --mattr GSEID=GSE14934 \
    --mattr genes_with_highest_var=250 \
    --run


8.  Still not quite right.  Looks a bit messy.  Let's cluster it.

$ betsy_run.py --network_png graph.png \
    --input GEOSeries \
    --output Heatmap --output_file heatmap.png \
    --dattr Heatmap.cluster_alg=hierarchical \
    --dattr SignalFile.filter_and_threshold=yes \
    --dattr SignalFile.gene_center=mean \
    --dattr SignalFile.gene_normalize=variance \
    --receipt "GSE14934.heatmap.txt" \
    --mattr GSEID=GSE14934 \
    --mattr genes_with_highest_var=250 \
    --run


9.  Looks much better.  Now refining by playing around with attributes
for the "plot_cluster_heatmap" module.  (You can find this by running
betsy_run.py and searching through the results.)


$ betsy_run.py \
    --input GEOSeries \
    --output Heatmap --output_file heatmap.png \
    --dattr Heatmap.cluster_alg=hierarchical \
    --dattr SignalFile.filter_and_threshold=yes \
    --dattr SignalFile.gene_center=mean \
    --dattr SignalFile.gene_normalize=variance \
    --receipt "GSE14934.heatmap.txt" \
    --mattr GSEID=GSE14934 \
    --mattr genes_with_highest_var=250 \
    --mattr hm_width=100 \
    --mattr hm_color=brewer-rdbu-div \
    --mattr hm_colorbar=yes \
    --mattr hm_colorbar_height=1.5 \
    --run

This generates a nice hierarchically clustered heatmap.


10.  Finally, I want to play around with the processing of the gene
expression data.  Previously, BETSY opted to use the data that was
provided by the depositors.  However, I would like to see what the
data looks like if it is preprocessed with RMA.  To do this, I ask for
the SignalFile to be preprocessed with RMA:
    --dattr SignalFile.preprocess=rma


$ betsy_run.py --network_png graph.png \
    --input GEOSeries \
    --output Heatmap --output_file heatmap.png \
    --dattr Heatmap.cluster_alg=hierarchical \
    --dattr SignalFile.preprocess=rma \
    --dattr SignalFile.filter_and_threshold=yes \
    --dattr SignalFile.gene_center=mean \
    --dattr SignalFile.gene_normalize=variance \
    --receipt "GSE14934.heatmap.txt" \
    --mattr GSEID=GSE14934 \
    --mattr genes_with_highest_var=250 \
    --mattr hm_width=100 \
    --mattr hm_color=brewer-rdbu-div \
    --mattr hm_colorbar=yes \
    --mattr hm_colorbar_height=1.5 \
    --run

Taking a look at the graph generated, the pipeline now:

a.  Downloaded the supplementary files associated with GEO record
    GSE14934.
b.  Saw that it contained Affymetrix CEL files.  
c.  Examined the CEL files and determine that they were version cc1.
d.  Converted them to CEL version 3, since this is required for
    programs later in the pipeline.
e.  Preprocessed the CEL files by RMA.
f.  Log normalized the data.
g.  Filtered the data.
h.  Plotted the heatmap.



IV.  BETSY COOKBOOK
===================

This section includes some generic BETSY rules that you can try out.
This is a work in progress, so please email if there are any problems
with these.  Also, please email if you have any to add.

There are examples of some file formats in Betsy/samples/.


A.  Run FastQC to check quality of a folder of FastQ files.

betsy_run.py \
  --input FastqFolder \
  --input SampleGroupFile \
  --output FastQCSummary

You will need to provide --input_file and --output_file arguments
describing where your files (or folders) are, e.g.:

  betsy_run.py \
    --input FastqFolder --input_file my_fastq_folder/ \
    --input SampleGroupFile --input_file samples.txt \
    --output FastQCSummary --output_file fastqc_results.xls

- FastqFolder is a folder (directory) of .fastq files (or compressed
  fastq files, e.g. .fastq.gz).
- SampleGroupFile is a file that links each fastq file with a sample
  name.  There is an example in Betsy/samples/.

For simplicity, we will leave out the --input_file and --output_file
in these commands.  BETSY can still generate the graphs without them.
However, before executing the pipelines, please fill in with your own
files.

This will run FastQC on each of the fastq files in your FastqFolder
and provide a summary of the results.  If you want the raw results
from FastQC, you can specify a FastQCFolder as the --output, e.g.:

  betsy_run.py \
    --input FastqFolder \
    --input SampleGroupFile \
    --output FastQCFolder


If you look at the results and decide you would like to see what
happens after trimming adapters, you can ask for the adapters to be
trimmed.  You will need to provide a fasta file with the adapter
sequences.  I use the one distributed with Trimmomatic.

  betsy_run.py \
    --input FastqFolder \
    --input SampleGroupFile \
    --output FastQCSummary \
    --dattr FastQCSummary.adapters_trimmed=yes \
    --mattr adapters_fasta=adapters/TruSeq3-PE-2.fa



B.  Preprocess RNA-Seq data starting from Fastq files.

betsy_run.py --network_png graph.png \
  --input FastqFolder \
  --input SampleGroupFile \
  --input ReferenceGenome \
  --input GTFGeneModel \
  --output SignalFile \
  --dattr SignalFile.preprocess=fpkm

This will generate a gene expression matrix (SignalFile) containing
the FPKM values.  Note from the terminal output (and from the graph)
that this will generate logged FPKM values.  If you don't want it to
be logged, then request for the SignalFile to be not logged:

  --dattr SignalFile.logged=no

Also, if you would like to get TPM, read counts, or counts per
million, you can specify one of:

  --dattr SignalFile.preprocess=tpm
  --dattr SignalFile.preprocess=counts
  --dattr SignalFile.preprocess=cpm

The pipelines will change to reflect the desired output.

Also note that these pipelines analyze the data without adapter
trimming.  To figure out how to request adapter trimming, let's start
by examining the graph.png created above.  Note that the SignalFile
data type that is generated does not have an attribute that controls
adapter trimming.  Thus, we cannot just set an attribute for
SignalFile.

While in principal each data type should contain attributes describing
every option used to create it, this would lead to data types that
contain a confusing number of attributes.  In this case, instead of
setting the attribute on the SignalFile at the end, we will configure
the "lowest" data type that contains the appropriate attribute.  In
this case, the RNASeqUnprocessedSignalFile node contains an
"adapters_trimmed" attribute.  This attribute is dropped (for
simplicity) when it gets converted to the next data type.  If we set:
  --dattr RNASeqUnprocessedSignalFile.adapters_trimmed=yes

... the backwards chainer will generate a pipeline that creates this
data object with adapters trimmed.

In this RNA-Seq analysis, the aligners require a GTFGeneModel to know
where the transcripts are in the genome.  This is just a GTF file that
is provided to the alignment algorithm.  These can be downloaded from
GENCODE, UCSC, or other databases, e.g.:
  gencodegenes.org -> Data : Human : Reference Releases : 19 -> 
    Comprehensive gene annotation (GTF)

The ReferenceGenome here can be either:
  1.  A FASTA formatted file that contains a reference genome,
      e.g. GRCh37.p13.genome.fa.
      If this is given, the BETSY  
  2.  A directory that contains the genome file along with the proper
      indexes.



C.  Creating pre-indexed reference genomes.

In recipe B above, you provide a ReferenceGenome.  Since the
RNA-Seq aligners (e.g. Tophat, STAR, etc.) require their own indexes
for the genome, BETSY will automatically create those indexes from the
ReferenceGenome.  BETSY will save those indexes in its cache and reuse
them the next time they are needed.

In practice, however, those indexes take a lot of disk space, and
sometimes I would like to use them outside of BETSY.  Thus, I usually
pre-index my references.

betsy_run.py \
  --input ReferenceGenome \
  --output FullyIndexedReferenceGenome --output_file <reference>

betsy_run.py \
  --input ReferenceGenome \
  --input GTFGeneModel \
  --output RSEMReferenceGenome --output_file <reference.rsem>

betsy_run.py \
  --input ReferenceGenome \
  --input GTFGeneModel \
  --output STARReferenceGenome --output_file <reference.star>

Note that the --output for an indexed "ReferenceGenome" is a
"FullyIndexedReferenceGenome".  This is for historical reasons and
may be changed in the future.

Now that we have the indexed reference genomes, we can ask BETSY to
use them when doing the RNA-Seq preprocessing.  The RNA-Seq recipe
(from above) then becomes:

betsy_run.py --network_png graph.png \
  --input FastqFolder \
  --input SampleGroupFile \
  --input ReferenceGenome \
  --input STARReferenceGenome --input_file <reference.star> \
  --input RSEMReferenceGenome --input_file <reference.rsem> \
  --input GTFGeneModel \
  --output SignalFile \
  --dattr SignalFile.preprocess=fpkm

We get a message that ReferenceGenome is no longer needed, so we can
remove it.  The final command is then:

betsy_run.py --network_png graph.png \
  --input FastqFolder \
  --input SampleGroupFile \
  --input STARReferenceGenome \
  --input RSEMReferenceGenome \
  --input GTFGeneModel \
  --output SignalFile \
  --dattr SignalFile.preprocess=fpkm




V.  MANAGING CACHE
==================

When BETSY runs pipelines, it tries to avoiding repeating the same
calculation.  This enables the user to try multiple different
parameters without performing redundant calculations.  BETSY does this
by caching the results in the CACHE_PATH configured in ~/.betsyrc.
Because CACHE_PATH contains an archive of every result, it can grow
large.  Unfortunately, there is not yet an automated way of clearing
that cache, and it must be done manually using a script called
betsy_manage_cache.py

Here are some example uses of betsy_manage_cache.py.

betsy_manage_cache.py -h        Show a help message.
betsy_manage_cache.py           Generates a summary of the analyses that are 
                                cached.
betsy_manage_cache.py --run     Show the analyses currently running.
betsy_manage_cache.py --broken  Show the broken analyses, e.g. those that 
                                quit before completion for some reason.

betsy_manage_cache.py --clear_cache 1T 
                                Clear out 1 terabyte of old (not currently 
                                running) analyses.
betsy_manage_cache.py --clear_cache 500g
                                Clear out 500 Gb of old analyses.
betsy_manage_cache.py --clear_cache 500g --dry_run
                                Do a dry run.  Just show the analyses that 
                                would be deleted without actually deleting
                                them.


BETSY will clear the analyses that were least recently accessed.
